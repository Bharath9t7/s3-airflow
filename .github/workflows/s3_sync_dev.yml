name: aws-s3-sync-dev

on:
  workflow_run:
    workflows: [CI Test Dev]
    types: [completed]
    branches:
      - dev
      
env:
  GITHUB_REF: "refs/heads/dev"

jobs:
  deploy:
    name: s3-sync-dev
    
    runs-on: ubuntu-latest
    environment: dev
    
    steps:
    - name: checkout
      uses: actions/checkout@v3
      with:
        ref: dev
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ap-south-1
        
#     - name: Sync changes to s3
#       run: aws s3 sync ./dags ${{vars.DEV_S3_BUCKET}} --delete

    - name: Find changed files
      id: find-changes
      run: |
        if [ $(git rev-parse --verify HEAD~1) ]; then
          echo $(git diff --name-only HEAD~1) > changed_files.txt
        else
          git ls-tree --name-only -r HEAD > changed_files.txt
        fi
          # Use the new outputs context to set the value of the files output
          echo "::set-output name=files::$(cat changed_files.txt)"
        # Use the new outputs context to declare the files output
        # This allows other steps to access the value of the files output
        # without having to parse the output of the previous step
        # The value of the files output will be a space-separated list of file names
        # e.g. "file1.txt file2.txt file3.txt"
        # The output will be available to other steps as "${{ steps.find-changes.outputs.files }}"
        outputs:
          files: ${{ steps.find-changes.outputs.files }}
          
    - name: Sync changed files to S3 bucket
      run: |
        for file in ${{ steps.find-changes.outputs.files }}; do
            aws s3 cp "$file" "s${{vars.DEV_S3_BUCKET}}/$file"
        done
